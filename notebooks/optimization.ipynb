{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../modules'))\n",
    "from optimizer import optimize_pipeline\n",
    "from preproc import PhishingDatasetPreproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = PhishingDatasetPreproc()\n",
    "dataset, X, y = prep.basic_operations()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials = {}\n",
    "model_names = ['KNN','DTR', 'SVM', 'RF', 'XGB', 'LGBM', 'MLP']\n",
    "selectors = ['tree', 'pca', 'univariate', 'l1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 03:02:15,267] A new study created in memory with name: optimization_KNN\n",
      "[I 2024-11-21 03:02:15,451] Trial 0 finished with value: 0.8885544433222741 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.19650156188774928, 'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 0 with value: 0.8885544433222741.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 03:02:16,859] Trial 1 finished with value: 0.9290802589377967 and parameters: {'fs_method': 'tree', 'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'chebyshev'}. Best is trial 1 with value: 0.9290802589377967.\n",
      "[I 2024-11-21 03:02:18,875] Trial 2 finished with value: 0.9252214226454962 and parameters: {'fs_method': 'tree', 'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean'}. Best is trial 1 with value: 0.9290802589377967.\n",
      "[I 2024-11-21 03:02:20,259] Trial 3 finished with value: 0.9276328045074896 and parameters: {'fs_method': 'tree', 'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'chebyshev'}. Best is trial 1 with value: 0.9290802589377967.\n",
      "[I 2024-11-21 03:02:20,582] Trial 4 finished with value: 0.8739618166363826 and parameters: {'fs_method': 'pca', 'selector__n_components': 4, 'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 1 with value: 0.9290802589377967.\n",
      "[I 2024-11-21 03:02:21,449] Trial 5 finished with value: 0.9437944581261984 and parameters: {'fs_method': 'univariate', 'selector__k': 18, 'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan'}. Best is trial 5 with value: 0.9437944581261984.\n",
      "[I 2024-11-21 03:02:22,251] Trial 6 finished with value: 0.9576649208797138 and parameters: {'fs_method': 'univariate', 'selector__k': 23, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan'}. Best is trial 6 with value: 0.9576649208797138.\n",
      "[I 2024-11-21 03:02:22,594] Trial 7 finished with value: 0.9318539588500346 and parameters: {'fs_method': 'univariate', 'selector__k': 10, 'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan'}. Best is trial 6 with value: 0.9576649208797138.\n",
      "[I 2024-11-21 03:02:23,191] Trial 8 finished with value: 0.9395730129403459 and parameters: {'fs_method': 'pca', 'selector__n_components': 25, 'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean'}. Best is trial 6 with value: 0.9576649208797138.\n",
      "c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:150: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] O sistema n√£o pode encontrar o arquivo especificado\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 227, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[I 2024-11-21 03:02:23,592] Trial 9 finished with value: 0.9527197848341211 and parameters: {'fs_method': 'pca', 'selector__n_components': 14, 'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 6 with value: 0.9576649208797138.\n",
      "[I 2024-11-21 03:02:24,145] Trial 10 finished with value: 0.9504280122823129 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 6 with value: 0.9576649208797138.\n",
      "[I 2024-11-21 03:02:24,620] Trial 11 finished with value: 0.9523584847354524 and parameters: {'fs_method': 'pca', 'selector__n_components': 12, 'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 6 with value: 0.9576649208797138.\n",
      "[I 2024-11-21 03:02:25,474] Trial 12 finished with value: 0.9568204573365587 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.0022406607976334547, 'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 6 with value: 0.9576649208797138.\n",
      "[I 2024-11-21 03:02:26,383] Trial 13 finished with value: 0.9580270935083048 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.0010723831001791492, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 13 with value: 0.9580270935083048.\n",
      "[I 2024-11-21 03:02:27,273] Trial 14 finished with value: 0.956338529976129 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.0013047431571731902, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan'}. Best is trial 13 with value: 0.9580270935083048.\n",
      "[I 2024-11-21 03:02:27,698] Trial 15 finished with value: 0.9310106586801095 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.020108926266204075, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'chebyshev'}. Best is trial 13 with value: 0.9580270935083048.\n",
      "[I 2024-11-21 03:02:28,345] Trial 16 finished with value: 0.9581472117942778 and parameters: {'fs_method': 'univariate', 'selector__k': 23, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan'}. Best is trial 16 with value: 0.9581472117942778.\n",
      "[I 2024-11-21 03:02:28,557] Trial 17 finished with value: 0.9371609039700838 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.01588218450554318, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan'}. Best is trial 16 with value: 0.9581472117942778.\n",
      "[I 2024-11-21 03:02:28,656] Trial 18 finished with value: 0.9015792791594046 and parameters: {'fs_method': 'univariate', 'selector__k': 2, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean'}. Best is trial 16 with value: 0.9581472117942778.\n",
      "c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_base.py:102: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  warnings.warn(\n",
      "[I 2024-11-21 03:02:28,671] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 failed: Found array with 0 feature(s) (shape=(6632, 0)) while a minimum of 1 is required by KNeighborsClassifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 03:02:29,532] Trial 20 finished with value: 0.9605596116078472 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:30,395] Trial 21 finished with value: 0.9605596116078472 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:31,271] Trial 22 finished with value: 0.9600772479824563 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:32,113] Trial 23 finished with value: 0.9600772479824563 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:32,982] Trial 24 finished with value: 0.9600772479824563 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:33,665] Trial 25 finished with value: 0.9588703936782299 and parameters: {'fs_method': 'univariate', 'selector__k': 24, 'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:34,470] Trial 26 finished with value: 0.9515133667948559 and parameters: {'fs_method': 'univariate', 'selector__k': 26, 'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:35,014] Trial 27 finished with value: 0.9529605303818556 and parameters: {'fs_method': 'univariate', 'selector__k': 18, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:35,788] Trial 28 finished with value: 0.9530814484869241 and parameters: {'fs_method': 'univariate', 'selector__k': 27, 'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:36,647] Trial 29 finished with value: 0.9293206409313968 and parameters: {'fs_method': 'univariate', 'selector__k': 12, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'chebyshev'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:37,413] Trial 30 finished with value: 0.9593530481469281 and parameters: {'fs_method': 'univariate', 'selector__k': 27, 'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:38,263] Trial 31 finished with value: 0.9600772479824563 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:39,105] Trial 32 finished with value: 0.9605596116078472 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:40,405] Trial 33 finished with value: 0.9217223595245002 and parameters: {'fs_method': 'tree', 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:41,696] Trial 34 finished with value: 0.9231698139548072 and parameters: {'fs_method': 'tree', 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:43,057] Trial 35 finished with value: 0.8591241544639722 and parameters: {'fs_method': 'univariate', 'selector__k': 27, 'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'chebyshev'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:43,854] Trial 36 finished with value: 0.9469306215103348 and parameters: {'fs_method': 'univariate', 'selector__k': 25, 'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:45,148] Trial 37 finished with value: 0.9217223595245002 and parameters: {'fs_method': 'tree', 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:46,045] Trial 38 finished with value: 0.9364364860020752 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:46,645] Trial 39 finished with value: 0.9548902030158997 and parameters: {'fs_method': 'univariate', 'selector__k': 21, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:47,754] Trial 40 finished with value: 0.9384872221628416 and parameters: {'fs_method': 'pca', 'selector__n_components': 30, 'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:48,594] Trial 41 finished with value: 0.9600772479824563 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:49,447] Trial 42 finished with value: 0.9600772479824563 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 20 with value: 0.9605596116078472.\n",
      "[I 2024-11-21 03:02:50,213] Trial 43 finished with value: 0.9609212752606501 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:50,992] Trial 44 finished with value: 0.9609212752606501 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:51,596] Trial 45 finished with value: 0.9582673300802508 and parameters: {'fs_method': 'univariate', 'selector__k': 27, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:51,825] Trial 46 finished with value: 0.8655172539156597 and parameters: {'fs_method': 'pca', 'selector__n_components': 2, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:53,204] Trial 47 finished with value: 0.85815804570748 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'chebyshev'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:54,464] Trial 48 finished with value: 0.923049259403873 and parameters: {'fs_method': 'tree', 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:55,110] Trial 49 finished with value: 0.946447167222541 and parameters: {'fs_method': 'univariate', 'selector__k': 21, 'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:55,792] Trial 50 finished with value: 0.9580265845325165 and parameters: {'fs_method': 'univariate', 'selector__k': 25, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:56,586] Trial 51 finished with value: 0.9609212752606501 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:57,378] Trial 52 finished with value: 0.9609212752606501 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:58,161] Trial 53 finished with value: 0.9609212752606501 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:58,785] Trial 54 finished with value: 0.9563378028678604 and parameters: {'fs_method': 'univariate', 'selector__k': 22, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:02:59,726] Trial 55 finished with value: 0.9544087846312579 and parameters: {'fs_method': 'pca', 'selector__n_components': 22, 'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:00,394] Trial 56 finished with value: 0.9580265845325165 and parameters: {'fs_method': 'univariate', 'selector__k': 25, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:01,251] Trial 57 finished with value: 0.9598357753264534 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:01,351] Trial 58 finished with value: 0.8596009920665215 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.09109947014642239, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:02,191] Trial 59 finished with value: 0.9598357753264534 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:02,400] Trial 60 finished with value: 0.9264258774924363 and parameters: {'fs_method': 'univariate', 'selector__k': 5, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'chebyshev'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:03,143] Trial 61 finished with value: 0.9609212752606501 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:03,857] Trial 62 finished with value: 0.9600769571391489 and parameters: {'fs_method': 'univariate', 'selector__k': 26, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:04,627] Trial 63 finished with value: 0.9601975844009101 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:05,301] Trial 64 finished with value: 0.9586293572871881 and parameters: {'fs_method': 'univariate', 'selector__k': 24, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:06,084] Trial 65 finished with value: 0.9605593934753667 and parameters: {'fs_method': 'univariate', 'selector__k': 28, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:06,817] Trial 66 finished with value: 0.9598356299047996 and parameters: {'fs_method': 'univariate', 'selector__k': 26, 'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_base.py:102: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  warnings.warn(\n",
      "[I 2024-11-21 03:03:06,826] Trial 67 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 failed: Found array with 0 feature(s) (shape=(6632, 0)) while a minimum of 1 is required by KNeighborsClassifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 03:03:07,393] Trial 68 finished with value: 0.9415023947310825 and parameters: {'fs_method': 'univariate', 'selector__k': 15, 'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:08,042] Trial 69 finished with value: 0.9579056664274482 and parameters: {'fs_method': 'univariate', 'selector__k': 23, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:09,403] Trial 70 finished with value: 0.9231698139548072 and parameters: {'fs_method': 'tree', 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 43 with value: 0.9609212752606501.\n",
      "[I 2024-11-21 03:03:10,227] Trial 71 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:11,034] Trial 72 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:11,852] Trial 73 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:12,641] Trial 74 finished with value: 0.9599560390340803 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:13,448] Trial 75 finished with value: 0.9605593934753667 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:14,230] Trial 76 finished with value: 0.9437951852344671 and parameters: {'fs_method': 'pca', 'selector__n_components': 8, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'chebyshev'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:14,941] Trial 77 finished with value: 0.9600769571391489 and parameters: {'fs_method': 'univariate', 'selector__k': 26, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:15,766] Trial 78 finished with value: 0.9510307123261577 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:16,620] Trial 79 finished with value: 0.9606800207371279 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:17,495] Trial 80 finished with value: 0.9416235309686319 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.005280803838633351, 'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:18,238] Trial 81 finished with value: 0.9603179208193637 and parameters: {'fs_method': 'univariate', 'selector__k': 27, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:19,040] Trial 82 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:19,860] Trial 83 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:20,677] Trial 84 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:21,490] Trial 85 finished with value: 0.9605593934753667 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:22,323] Trial 86 finished with value: 0.9605596116078472 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:23,035] Trial 87 finished with value: 0.9582678390560389 and parameters: {'fs_method': 'univariate', 'selector__k': 26, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:24,399] Trial 88 finished with value: 0.9264271135764929 and parameters: {'fs_method': 'tree', 'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:25,217] Trial 89 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:25,899] Trial 90 finished with value: 0.8702204810402885 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'chebyshev'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:26,693] Trial 91 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:27,481] Trial 92 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:28,273] Trial 93 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:29,062] Trial 94 finished with value: 0.9610419025224113 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:29,879] Trial 95 finished with value: 0.9605596116078472 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:30,647] Trial 96 finished with value: 0.9545287574955774 and parameters: {'fs_method': 'pca', 'selector__n_components': 20, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:31,520] Trial 97 finished with value: 0.9363160041619677 and parameters: {'fs_method': 'univariate', 'selector__k': 27, 'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:31,755] Trial 98 finished with value: 0.9325783041072165 and parameters: {'fs_method': 'univariate', 'selector__k': 9, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:32,555] Trial 99 finished with value: 0.9599560390340803 and parameters: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 71 with value: 0.9610419025224113.\n",
      "[I 2024-11-21 03:03:32,555] A new study created in memory with name: optimization_DTR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 0.9610419025224113\n",
      "Params:\n",
      "  fs_method: univariate\n",
      "  selector__k: 29\n",
      "  n_neighbors: 4\n",
      "  weights: distance\n",
      "  algorithm: ball_tree\n",
      "  metric: manhattan\n",
      "DTR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 03:03:32,854] Trial 0 finished with value: 0.880834225858733 and parameters: {'fs_method': 'pca', 'selector__n_components': 20, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.880834225858733.\n",
      "[I 2024-11-21 03:03:32,894] Trial 1 finished with value: 0.8002687392160756 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 0 with value: 0.880834225858733.\n",
      "[I 2024-11-21 03:03:32,924] Trial 2 finished with value: 0.9282348501538925 and parameters: {'fs_method': 'univariate', 'selector__k': 6, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:33,072] Trial 3 finished with value: 0.8761288901201256 and parameters: {'fs_method': 'pca', 'selector__n_components': 25, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:33,423] Trial 4 finished with value: 0.8733564990027709 and parameters: {'fs_method': 'pca', 'selector__n_components': 21, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:33,456] Trial 5 finished with value: 0.896994788815039 and parameters: {'fs_method': 'univariate', 'selector__k': 5, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:33,687] Trial 6 finished with value: 0.8357250832720744 and parameters: {'fs_method': 'pca', 'selector__n_components': 15, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:33,715] Trial 7 finished with value: 0.8994071159177814 and parameters: {'fs_method': 'univariate', 'selector__k': 11, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:33,744] Trial 8 finished with value: 0.9154507598644962 and parameters: {'fs_method': 'univariate', 'selector__k': 3, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:33,773] Trial 9 finished with value: 0.9277535771909043 and parameters: {'fs_method': 'univariate', 'selector__k': 7, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:34,976] Trial 10 finished with value: 0.9230488958497387 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:35,040] Trial 11 finished with value: 0.9149697050339887 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.001266076497193798, 'criterion': 'gini', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:35,082] Trial 12 finished with value: 0.9168984324272836 and parameters: {'fs_method': 'univariate', 'selector__k': 14, 'criterion': 'gini', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:36,280] Trial 13 finished with value: 0.9255817775034156 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_base.py:102: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  warnings.warn(\n",
      "[I 2024-11-21 03:03:36,299] Trial 14 pruned. \n",
      "[I 2024-11-21 03:03:36,339] Trial 15 finished with value: 0.9222050867040255 and parameters: {'fs_method': 'univariate', 'selector__k': 8, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:36,379] Trial 16 finished with value: 0.9135197784355684 and parameters: {'fs_method': 'univariate', 'selector__k': 21, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:36,413] Trial 17 finished with value: 0.8885544433222741 and parameters: {'fs_method': 'univariate', 'selector__k': 1, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:36,456] Trial 18 finished with value: 0.9225671139109627 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.023561439793721405, 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 failed: Found array with 0 feature(s) (shape=(6632, 0)) while a minimum of 1 is required by DecisionTreeClassifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 03:03:37,631] Trial 19 finished with value: 0.9263059046281169 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:37,679] Trial 20 finished with value: 0.9161753232541585 and parameters: {'fs_method': 'univariate', 'selector__k': 18, 'criterion': 'gini', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9282348501538925.\n",
      "[I 2024-11-21 03:03:38,896] Trial 21 finished with value: 0.9310101497043215 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.9310101497043215.\n",
      "[I 2024-11-21 03:03:40,062] Trial 22 finished with value: 0.9346277314730997 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.9346277314730997.\n",
      "[I 2024-11-21 03:03:41,225] Trial 23 finished with value: 0.9283561318130953 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.9346277314730997.\n",
      "[I 2024-11-21 03:03:42,391] Trial 24 finished with value: 0.929321513461319 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.9346277314730997.\n",
      "[I 2024-11-21 03:03:43,571] Trial 25 finished with value: 0.9252210590913619 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.9346277314730997.\n",
      "[I 2024-11-21 03:03:44,735] Trial 26 finished with value: 0.910144251009408 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.9346277314730997.\n",
      "[I 2024-11-21 03:03:45,911] Trial 27 finished with value: 0.9287172864901102 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.9346277314730997.\n",
      "[I 2024-11-21 03:03:47,083] Trial 28 finished with value: 0.934386549660404 and parameters: {'fs_method': 'tree', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 22 with value: 0.9346277314730997.\n",
      "[I 2024-11-21 03:03:48,261] Trial 29 finished with value: 0.9347484314456874 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 29 with value: 0.9347484314456874.\n",
      "[I 2024-11-21 03:03:49,441] Trial 30 finished with value: 0.9351103859417979 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.9351103859417979.\n",
      "[I 2024-11-21 03:03:50,619] Trial 31 finished with value: 0.9352312313360397 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 31 with value: 0.9352312313360397.\n",
      "[I 2024-11-21 03:03:51,836] Trial 32 finished with value: 0.9347484314456876 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 31 with value: 0.9352312313360397.\n",
      "[I 2024-11-21 03:03:53,055] Trial 33 finished with value: 0.9354720495946008 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:03:54,354] Trial 34 finished with value: 0.9347485041565143 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:03:55,535] Trial 35 finished with value: 0.9352310859143858 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:03:55,768] Trial 36 finished with value: 0.6248922607322999 and parameters: {'fs_method': 'pca', 'selector__n_components': 1, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:03:56,961] Trial 37 finished with value: 0.9351103132309712 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:03:57,147] Trial 38 finished with value: 0.7822934594429916 and parameters: {'fs_method': 'pca', 'selector__n_components': 6, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:03:58,319] Trial 39 finished with value: 0.9335425223822102 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:03:59,508] Trial 40 finished with value: 0.910264514717035 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:04:00,817] Trial 41 finished with value: 0.9343869859253653 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:04:01,975] Trial 42 finished with value: 0.9345073950546456 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "[I 2024-11-21 03:04:03,200] Trial 43 finished with value: 0.9342657042661623 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 33 with value: 0.9354720495946008.\n",
      "c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_base.py:102: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  warnings.warn(\n",
      "[I 2024-11-21 03:04:03,220] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 failed: Found array with 0 feature(s) (shape=(6632, 0)) while a minimum of 1 is required by DecisionTreeClassifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 03:04:04,421] Trial 45 finished with value: 0.9355928222780158 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:04,542] Trial 46 finished with value: 0.7389925624095205 and parameters: {'fs_method': 'pca', 'selector__n_components': 30, 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:05,724] Trial 47 finished with value: 0.9346277314730995 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:06,890] Trial 48 finished with value: 0.9349897586800366 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:06,958] Trial 49 finished with value: 0.8977209518428924 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.0013292645513619957, 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:08,165] Trial 50 finished with value: 0.932336540607906 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:09,384] Trial 51 finished with value: 0.9341456586910161 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:10,567] Trial 52 finished with value: 0.9348693495507561 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:11,751] Trial 53 finished with value: 0.9348692041291023 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:12,965] Trial 54 finished with value: 0.9351103859417979 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:14,175] Trial 55 finished with value: 0.9342657769769893 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:15,395] Trial 56 finished with value: 0.9337838496165596 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:15,659] Trial 57 finished with value: 0.8988042704522832 and parameters: {'fs_method': 'pca', 'selector__n_components': 11, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:16,847] Trial 58 finished with value: 0.9300449861885787 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:16,895] Trial 59 finished with value: 0.9079719423461313 and parameters: {'fs_method': 'l1', 'selector__alpha': 0.04926746795923219, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:18,081] Trial 60 finished with value: 0.9348690587074486 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:19,292] Trial 61 finished with value: 0.9343864769495772 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:20,523] Trial 62 finished with value: 0.9353515677544934 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:21,705] Trial 63 finished with value: 0.9343868405037116 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:22,917] Trial 64 finished with value: 0.9318544678258227 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:24,108] Trial 65 finished with value: 0.9353514950436663 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:24,158] Trial 66 finished with value: 0.8994098062183753 and parameters: {'fs_method': 'univariate', 'selector__k': 30, 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:25,381] Trial 67 finished with value: 0.934868840574968 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:26,582] Trial 68 finished with value: 0.9353516404653203 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[I 2024-11-21 03:04:27,798] Trial 69 finished with value: 0.9323363951862526 and parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 45 with value: 0.9355928222780158.\n",
      "[W 2024-11-21 03:04:28,682] Trial 70 failed with parameters: {'fs_method': 'tree', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\OneDrive\\Documentos\\Mestrado\\Semestre 2\\Minera√ß√£o\\crisp_dm_phishing\\modules\\optimizer.py\", line 76, in objective\n",
      "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring, error_score='raise')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 562, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 309, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1051, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_from_model.py\", line 358, in fit\n",
      "    self.estimator_.fit(X, y, **fit_params)\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1051, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 297, in _fit\n",
      "    self.n_classes_.append(classes_k.shape[0])\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-21 03:04:28,691] Trial 70 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[1;32m----> 3\u001b[0m     best_trials[model_name] \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselectors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\OneDrive\\Documentos\\Mestrado\\Semestre 2\\Minera√ß√£o\\crisp_dm_phishing\\modules\\optimizer.py:85\u001b[0m, in \u001b[0;36moptimize_pipeline\u001b[1;34m(X, y, model_name, fs_methods, n_trials, cv_folds, scoring)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Create and run the Optuna study\u001b[39;00m\n\u001b[0;32m     84\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimization_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Print the best trial\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32mc:\\Users\\giull\\OneDrive\\Documentos\\Mestrado\\Semestre 2\\Minera√ß√£o\\crisp_dm_phishing\\modules\\optimizer.py:76\u001b[0m, in \u001b[0;36moptimize_pipeline.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     73\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mcv_folds, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    415\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 416\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:370\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    368\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 370\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 950\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_from_model.py:358\u001b[0m, in \u001b[0;36mSelectFromModel.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_ \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_\u001b[38;5;241m.\u001b[39mfeature_names_in_\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\giull\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:297\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    295\u001b[0m     classes_k, y_encoded[:, k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y[:, k], return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mappend(classes_k)\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\u001b[38;5;241m.\u001b[39mappend(classes_k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    298\u001b[0m y \u001b[38;5;241m=\u001b[39m y_encoded\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    best_trials[model_name] = optimize_pipeline(X_train, y_train, model_name, selectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fs_method': 'univariate',\n",
       " 'selector__k': 29,\n",
       " 'n_neighbors': 4,\n",
       " 'weights': 'distance',\n",
       " 'algorithm': 'ball_tree',\n",
       " 'metric': 'manhattan'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trials['KNN'].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN had best trial with params: {'fs_method': 'univariate', 'selector__k': 29, 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'} and accuracy 0.9610419025224113\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'DTR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m had best trial with params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbest_trials\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_trials[model_name]\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DTR'"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(f'{model_name} had best trial with params: {best_trials[model_name].params} and accuracy {best_trials[model_name].value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
